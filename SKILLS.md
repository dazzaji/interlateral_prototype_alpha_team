# Skills Index (Quick Reference)

Canonical source-of-truth for skills:
`.agent/skills/`

Agent-specific deployment copies:
- `.claude/skills/` (for CC)
- `.codex/skills/` (for Codex)

**Note:** `projects/` is reserved for downstream users. Do NOT put system skills there.

---

## add-comments

**Purpose:** Add reviews/comments to shared files without overwriting other agents.

**Canonical location:**
`.agent/skills/add-comments/SKILL.md`

**Example prompt(s):**
```
"Run the add-comments skill at .agent/skills/add-comments/SKILL.md.
Add your review to projects/reviews.md"
```

---

## dev-collaboration

**Purpose:** Tri-agent collaboration pattern (Drafter / Reviewer / Breaker).

**Canonical location:**
`.agent/skills/dev-collaboration/SKILL.md`

**Example prompt(s):**
```
"Run the dev-collaboration skill at .agent/skills/dev-collaboration/SKILL.md.
Your role is REVIEWER.
The Drafter is CC, the Breaker is Codex.
Artifact location: dev_plan/dev_plan.md
Deliver your review using the add-comments skill to projects/plan_reviews.md"
```

---

## adherence-check

**Purpose:** Check artifacts against INTERNALS_CONFORMANCE.md and report violations.

**Canonical location:**
`.agent/skills/adherence-check/SKILL.md`

**Example prompt(s):**
```
"Run the adherence-check skill at .agent/skills/adherence-check/SKILL.md.
Check: dev_plan/dev_plan.md
Report to: projects/conformance_results.md
Notify me when complete."
```

---

## evals

**Purpose:** Run the OTEL eval workflow end-to-end and report JSON/Markdown outputs. Use evals to validate agent work quality, review patterns, and approval chains.

**When to use:**
- After completing a dev plan (quality gate before reporting "done")
- Before PR (pre-commit quality validation)
- During tri-agent collaboration (validate review patterns worked)
- When asked to "run evals" or "evaluate" work

**Canonical location:**
`.agent/skills/evals/SKILL.md`

**Full Documentation:** `interlateral_comms_monitor/docs/EVALS_GUIDE.md`

**Prerequisites:**
1. `.env` file in repo root with `OPENAI_API_KEY=sk-...`
2. Python deps installed: `pip install -r corpbot_agent_evals/lake_merritt/requirements.txt`
3. OTEL traces in `.observability/traces/` (generated by observability system)

**Eval Packs Available:**
| Pack | What It Checks |
|------|----------------|
| `revision_addressed` | All Breaker issues were fixed in revisions |
| `reviewer_minimum` | Reviewer provided >= 3 suggestions |
| `approval_chain` | All agents approved before completion |
| `review_timing` | Reviews completed before revision started |
| `decline_percentage` | Ratio of declined vs addressed issues |
| `token_cost` | Total token usage for the skill run |
| `courier_usage` | Codex used courier (not direct injection) |

**Example prompt(s):**
```
"Run the evals skill at .agent/skills/evals/SKILL.md.
Trace: .observability/traces/dev-collaboration_*.json
Packs: revision_addressed, reviewer_minimum, approval_chain
Report to me: artifact location + eval report paths + pass/fail summary"
```

**Output:**
- JSON report: `.observability/evals/<pack>_<timestamp>.json`
- Markdown report: `.observability/evals/<pack>_<timestamp>.md`

**Quick Manual Test:**
```bash
# Use last_trace.txt (more reliable than ls -t)
TRACE=$(cat .observability/last_trace.txt)
./scripts/run-skill-eval.sh "$TRACE" revision_addressed
cat .observability/evals/revision_addressed_*.md
```

**See Also:**
- Full skill definition: `.agent/skills/evals/SKILL.md`
- Conformance rules: `INTERNALS_CONFORMANCE.md` Section 15
- Technical guide: `INTERNALS_GUIDE.md` Section 5B

---

## dev-competition

**Purpose:** Blind dual-implementation pattern where two agents independently create artifacts, then a third agent judges which is better.

**Canonical location:**
`.agent/skills/dev-competition/SKILL.md`

**Example prompt(s):**
```
"Run the dev-competition skill at .agent/skills/dev-competition/SKILL.md.
Competition directory: projects/experiments/feature_x/
Requirement: [describe what to build]
Assign roles:
- Implementer A: CC
- Implementer B: AG
- Judge: Codex
Start Phase 1 setup, then dispatch to implementers."
```

---

## hyperdomo

**Purpose:** Manager Agent that orchestrates Worker Agents (CC-Worker, AG, Codex) to execute Project Skills autonomously. Replaces the human orchestrator role.

**Type:** Manager Agent (general orchestration substrate)

**Canonical location:**
`.agent/skills/hyperdomo/SKILL.md`

**Capabilities:**
- Wake/monitor/inject/nudge Worker Agents
- Run tokens for signal isolation
- State persistence and resumption
- Security guardrails (allowlisted commands)
- Generic reporting framework

**Primitives Provided:**
| Primitive | Description |
|-----------|-------------|
| `WAKE_WORKERS` | Wake all Worker Agents, wait for ACKs |
| `SEND_PROMPT` | Send prompt file to agent |
| `WAIT_SIGNAL` | Wait for tokened signal |
| `REVIEW_GATE` | Manage revision loop until approval |
| `NUDGE` | Send nudge from library |
| `ASSERT/CHECK` | Pre/post condition verification |

**Example prompt(s):**
```
"HyperDomo, run test-4-series with TEST_ID=4B"
"Start HyperDomo and tell it to run the code-review-sprint project"
```

**See Also:**
- Project Skill: `.agent/skills/test-4-series/SKILL.md`
- Design document: `test_AUTORUN_SEQUENCE_FOR_REAL.md`

---

## test-4-series

**Purpose:** Test 4 Series project skill - dev-collaboration evaluation tests (4A, 4B, 4C, 4D). Hot-swappable plugin for HyperDomo.

**Type:** Project Skill (HyperDomo-compatible)

**Canonical location:**
`.agent/skills/test-4-series/SKILL.md`

**Worker Roles:**
- CC-Worker: DRAFTER
- AG: REVIEWER
- Codex: BREAKER

**Eval Packs:**
- `revision_addressed`
- `reviewer_minimum`
- `approval_chain`

**Phases:**
1. PREPARATION - Load prior learnings and test prompt
2. WAKE - Wake Worker Agents, wait for ACKs
3. ASSIGNMENT - Inject assignment to CC-Worker
4. REVIEW_GATE - Monitor for SKILL COMPLETE
5. POSTFLIGHT - Run harvest, export
6. EVALUATION - Run eval packs
7. REPORTING - Create reports

**Example prompt(s):**
```
"HyperDomo, run test-4-series with TEST_ID=4B"
```

**See Also:**
- Manager Agent: `.agent/skills/hyperdomo/SKILL.md`
- Test report format: `test_4A_FinalReport.md`

---

## Light Pattern Skills (Design Patterns)

The following six skills implement reusable multi-agent collaboration patterns. They define ROLES; prompts assign AGENTS.

---

## peer-collaboration

**Purpose:** Two agents co-create an artifact through turn-based iteration until both signal DONE.

**Weight:** Light (minimal ceremony)

**Canonical location:**
`.agent/skills/peer-collaboration/SKILL.md`

**Example prompt(s):**
```
"Build a todo API spec. Use peer-collaboration. CC is PEER_A, CX is PEER_B.
Output: projects/api/spec.md"
```

---

## negotiation

**Purpose:** Agents with competing priorities reach consensus through structured trade-offs.

**Weight:** Medium

**Canonical location:**
`.agent/skills/negotiation/SKILL.md`

**Example prompt(s):**
```
"Use negotiation for auth protocol design.
CC=Reliability, CX=Speed, GM=Security.
Output: projects/auth/protocol.md"
```

---

## constitutional

**Purpose:** Multiple agents draft a structured document through federated co-authorship and formal voting.

**Weight:** Heavy (formal phases, voting, ratification)

**Canonical location:**
`.agent/skills/constitutional/SKILL.md`

**Example prompt(s):**
```
"Use constitutional for Team Charter.
Sections: Communication, Decisions, Conflict.
LEAD=CC. Co-authors: Communication=[CC,CX], Decisions=[CX,GM], Conflict=[GM,CC].
Output: projects/team/charter.md"
```

---

## hierarchical

**Purpose:** Boss delegates tasks to workers, reviews their output, and approves or requests changes.

**Weight:** Medium

**Canonical location:**
`.agent/skills/hierarchical/SKILL.md`

**Example prompt(s):**
```
"Use hierarchical to write a press release.
BOSS=CC. WORKER=CX (headline), WORKER=GM (body).
Output: projects/press/release.md"
```

---

## democratic

**Purpose:** All agents have equal voice; decisions made by majority vote.

**Weight:** Medium

**Canonical location:**
`.agent/skills/democratic/SKILL.md`

**Example prompt(s):**
```
"Use democratic to decide on project priorities.
Members: CC, CX, GM. FACILITATOR=CC.
Output: projects/decisions.md"
```

---

## competition

**Purpose:** Agents work in parallel on the same task; judges evaluate and select the winner.

**Weight:** Heavy

**Canonical location:**
`.agent/skills/competition/SKILL.md`

**Example prompt(s):**
```
"Use competition to design a logo concept.
Competitors: CX, GM. Judge: CC.
Criteria: Memorable, Clear, Appealing.
Output: projects/logo/winner.md"
```

---

## publication-pipeline

**Purpose:** Three-round editorial review (review + red-team, political analysis, copy-edit) before publication.

**Weight:** Heavy

**Canonical location:**
`.agent/skills/publication-pipeline/SKILL.md`

**Example prompt(s):**
```
"Use publication-pipeline to write a blog post about Interlateral.
Read work.md first: projects/interlateral-blog/work.md
DRAFTER=CC, REVIEWER=CX, REDTEAM=GM, ANALYST=CX, EDITOR=GM, PUBLISHER=CC.
Output: projects/interlateral-blog/post.md"
```

---

Notes:
- `.agent/skills/` is the canonical source of truth for all skills.
- Deployment copies:
  - `.claude/skills/` - For CC (Claude Code CLI)
  - `.codex/skills/` - For Codex (OpenAI CLI, sandboxed)
  - AG reads from `.agent/skills/` directly (no copy needed - AG has full filesystem access)
- Sync via `scripts/deploy-skills.sh` after editing canonical source.
- Skills use the intersection standard (`name` matches folder, single-line `description`).
- `projects/` is reserved for downstream user projects - do NOT put system skills there.
